{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the user configs\n",
    "with open('room_recognition/conf/conf_xgboost.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "\n",
    "seed      = config[\"seed\"]\n",
    "train_features_path   = config[\"train_features_path\"]\n",
    "train_labels_path   = config[\"train_labels_path\"]\n",
    "test_features_path   = config[\"test_features_path\"]\n",
    "test_labels_path   = config[\"test_labels_path\"]\n",
    "\n",
    "results     = config[\"results\"]\n",
    "classifier_path = config[\"classifier_path\"]\n",
    "\n",
    "num_classes   = config[\"num_classes\"]\n",
    "\n",
    "model_path=config[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train features and labels\n",
    "h5f_data_train  = h5py.File(train_features_path, 'r')\n",
    "h5f_label_train = h5py.File(train_labels_path, 'r')\n",
    "\n",
    "train_features_string = h5f_data_train['dataset_1']\n",
    "train_labels_string   = h5f_label_train['dataset_1']\n",
    "\n",
    "trainfeatures = np.array(train_features_string)\n",
    "trainlabels   = np.array(train_labels_string)\n",
    "\n",
    "h5f_data_train.close()\n",
    "h5f_label_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (1040, 2048)\n",
      "[INFO] labels shape: (1040,)\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of features and labels\n",
    "print (\"[INFO] features shape: {}\".format(trainfeatures.shape))\n",
    "print (\"[INFO] labels shape: {}\".format(trainlabels.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f_data_test  = h5py.File(test_features_path, 'r')\n",
    "h5f_label_test = h5py.File(test_labels_path, 'r')\n",
    "\n",
    "test_features_string = h5f_data_test['dataset_1']\n",
    "test_labels_string   = h5f_label_test['dataset_1']\n",
    "\n",
    "testfeatures = np.array(test_features_string)\n",
    "testlabels   = np.array(test_labels_string)\n",
    "\n",
    "h5f_data_test.close()\n",
    "h5f_label_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (160, 2048)\n",
      "[INFO] labels shape: (160,)\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of features and labels\n",
    "print (\"[INFO] features shape: {}\".format(testfeatures.shape))\n",
    "print (\"[INFO] labels shape: {}\".format(testlabels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(trainfeatures, label=trainlabels) \n",
    "dtest = xgb.DMatrix(testfeatures, label=testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective': 'multi:softmax'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters num_boost_round and early_stopping_rounds\n",
    "From https://cambridgespark.com/content/tutorials/hyperparameter-tuning-in-xgboost/index.html\n",
    "Since trees are built sequentially, instead of fixing the number of rounds at the beginning, we can test our model at each step and see if adding a new tree/round improves performance.\n",
    "\n",
    "To do so, we define a test dataset and a metric that is used to assess performance at each round. If performance haven't improved for N rounds (N is defined by the variable early_stopping_round), we stop the training and keep the best number of boosting rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"merror\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['num_class'] = 8\n",
    "params['silent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.29375\n",
      "Will train until Test-merror hasn't improved in 10 rounds.\n",
      "[1]\tTest-merror:0.25\n",
      "[2]\tTest-merror:0.25625\n",
      "[3]\tTest-merror:0.23125\n",
      "[4]\tTest-merror:0.21875\n",
      "[5]\tTest-merror:0.1875\n",
      "[6]\tTest-merror:0.18125\n",
      "[7]\tTest-merror:0.1875\n",
      "[8]\tTest-merror:0.18125\n",
      "[9]\tTest-merror:0.1875\n",
      "[10]\tTest-merror:0.175\n",
      "[11]\tTest-merror:0.175\n",
      "[12]\tTest-merror:0.1625\n",
      "[13]\tTest-merror:0.1625\n",
      "[14]\tTest-merror:0.15625\n",
      "[15]\tTest-merror:0.15625\n",
      "[16]\tTest-merror:0.15625\n",
      "[17]\tTest-merror:0.15625\n",
      "[18]\tTest-merror:0.15625\n",
      "[19]\tTest-merror:0.15\n",
      "[20]\tTest-merror:0.15\n",
      "[21]\tTest-merror:0.15\n",
      "[22]\tTest-merror:0.15\n",
      "[23]\tTest-merror:0.15\n",
      "[24]\tTest-merror:0.14375\n",
      "[25]\tTest-merror:0.15\n",
      "[26]\tTest-merror:0.14375\n",
      "[27]\tTest-merror:0.14375\n",
      "[28]\tTest-merror:0.14375\n",
      "[29]\tTest-merror:0.14375\n",
      "[30]\tTest-merror:0.1375\n",
      "[31]\tTest-merror:0.14375\n",
      "[32]\tTest-merror:0.14375\n",
      "[33]\tTest-merror:0.1375\n",
      "[34]\tTest-merror:0.1375\n",
      "[35]\tTest-merror:0.1375\n",
      "[36]\tTest-merror:0.13125\n",
      "[37]\tTest-merror:0.13125\n",
      "[38]\tTest-merror:0.13125\n",
      "[39]\tTest-merror:0.13125\n",
      "[40]\tTest-merror:0.13125\n",
      "[41]\tTest-merror:0.13125\n",
      "[42]\tTest-merror:0.13125\n",
      "[43]\tTest-merror:0.13125\n",
      "[44]\tTest-merror:0.13125\n",
      "[45]\tTest-merror:0.13125\n",
      "[46]\tTest-merror:0.13125\n",
      "Stopping. Best iteration:\n",
      "[36]\tTest-merror:0.13125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MERROR: 0.13 with 37 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MERROR: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301923</td>\n",
       "      <td>0.036665</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.007624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.254808</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243269</td>\n",
       "      <td>0.020757</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222115</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218269</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.218269</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.214423</td>\n",
       "      <td>0.022052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203846</td>\n",
       "      <td>0.022468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200962</td>\n",
       "      <td>0.022219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.202885</td>\n",
       "      <td>0.024963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.027802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.199038</td>\n",
       "      <td>0.030039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.193269</td>\n",
       "      <td>0.029854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.025979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.024057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.178846</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.178846</td>\n",
       "      <td>0.027264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.177885</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.177884</td>\n",
       "      <td>0.028685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.176923</td>\n",
       "      <td>0.027433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.026612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.175961</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.175961</td>\n",
       "      <td>0.028621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.027298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.172115</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.172115</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.172115</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.172115</td>\n",
       "      <td>0.028750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.170192</td>\n",
       "      <td>0.026086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.172115</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.173077</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.171154</td>\n",
       "      <td>0.025549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.027534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0           0.301923         0.036665           0.026923          0.007624\n",
       "1           0.254808         0.025258           0.006971          0.001923\n",
       "2           0.243269         0.020757           0.002404          0.001317\n",
       "3           0.222115         0.015916           0.001442          0.000899\n",
       "4           0.218269         0.022876           0.000721          0.000589\n",
       "5           0.218269         0.022261           0.000481          0.000589\n",
       "6           0.214423         0.022052           0.000000          0.000000\n",
       "7           0.203846         0.022468           0.000000          0.000000\n",
       "8           0.200962         0.022219           0.000000          0.000000\n",
       "9           0.202885         0.024963           0.000000          0.000000\n",
       "10          0.200000         0.027802           0.000000          0.000000\n",
       "11          0.199038         0.030039           0.000000          0.000000\n",
       "12          0.193269         0.029854           0.000000          0.000000\n",
       "13          0.187500         0.024889           0.000000          0.000000\n",
       "14          0.187500         0.025979           0.000000          0.000000\n",
       "15          0.184615         0.025184           0.000000          0.000000\n",
       "16          0.184615         0.025184           0.000000          0.000000\n",
       "17          0.180769         0.024057           0.000000          0.000000\n",
       "18          0.178846         0.029386           0.000000          0.000000\n",
       "19          0.178846         0.027264           0.000000          0.000000\n",
       "20          0.177885         0.026682           0.000000          0.000000\n",
       "21          0.177884         0.028685           0.000000          0.000000\n",
       "22          0.176923         0.027433           0.000000          0.000000\n",
       "23          0.175000         0.026612           0.000000          0.000000\n",
       "24          0.175961         0.028621           0.000000          0.000000\n",
       "25          0.175000         0.028621           0.000000          0.000000\n",
       "26          0.175961         0.028621           0.000000          0.000000\n",
       "27          0.173077         0.028846           0.000000          0.000000\n",
       "28          0.173077         0.028034           0.000000          0.000000\n",
       "29          0.175000         0.027298           0.000000          0.000000\n",
       "30          0.175000         0.029260           0.000000          0.000000\n",
       "31          0.173077         0.028846           0.000000          0.000000\n",
       "32          0.172115         0.027601           0.000000          0.000000\n",
       "33          0.172115         0.027094           0.000000          0.000000\n",
       "34          0.172115         0.027601           0.000000          0.000000\n",
       "35          0.172115         0.028750           0.000000          0.000000\n",
       "36          0.170192         0.026086           0.000000          0.000000\n",
       "37          0.172115         0.024777           0.000000          0.000000\n",
       "38          0.169231         0.025693           0.000000          0.000000\n",
       "39          0.173077         0.024134           0.000000          0.000000\n",
       "40          0.171154         0.025549           0.000000          0.000000\n",
       "41          0.168269         0.027534           0.000000          0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=seed,\n",
    "    nfold=5,\n",
    "    metrics={'merror'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.168269"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-merror-mean'].min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters max_depth and min_child_weight:\n",
    "Those parameters add constraints on the architecture of the trees.\n",
    "\n",
    "max_depth is the maximum number of nodes allowed from the root to the farthest leaf of a tree. Deeper trees can model more complex relationships by adding more nodes, but as we go deeper, splits become less relevant and are sometimes only due to noise, causing the model to overfit.\n",
    "min_child_weight is the minimum weight (or number of samples if all samples have a weight of 1) required in order to create a new node in the tree. A smaller min_child_weight allows the algorithm to create children that correspond to fewer samples, thus allowing for more complex trees, but again, more likely to overfit.\n",
    "Thus, those parameters can be used to control the complexity of the trees. It is important to tune them together in order to find a good trade-off between model bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment:\n",
    "\n",
    "float(\"Inf\") It acts as an unbounded upper value for comparison. This is useful for finding lowest values for something. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMERROR 0.1586538 for 32 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMERROR 0.15961540000000002 for 42 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMERROR 0.160577 for 47 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMERROR 0.1586538 for 32 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMERROR 0.15961540000000002 for 42 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMERROR 0.160577 for 47 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMERROR 0.1586538 for 32 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMERROR 0.15961540000000002 for 42 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMERROR 0.160577 for 47 rounds\n",
      "Best params: 9, 5, MERROR: 0.1586538\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_merror = float(\"Inf\")  \n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=seed,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best score with a max_depth of 9 and min_child_weight of 5 ,  MERROR=0.158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 9\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters subsample and colsample_bytree\n",
    "Those parameters control the sampling of the dataset that is done at each boosting round.\n",
    "\n",
    "Instead of using the whole training set every time, we can build a tree on slightly different data at each step, which makes it less likely to overfit to a single sample or feature.\n",
    "\n",
    "subsample corresponds to the fraction of observations (the rows) to subsample at each step. By default it is set to 1 meaning that we use all rows.\n",
    "colsample_bytree corresponds to the fraction of features (the columns) to use. By default it is set to 1 meaning that we will use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMERROR 0.1586538 for 32 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMERROR 0.1567306 for 30 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMERROR 0.1625 for 22 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMERROR 0.14807679999999998 for 51 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMERROR 0.1615384 for 17 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMERROR 0.1740384 for 27 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMERROR 0.1596152 for 26 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMERROR 0.1634614 for 56 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMERROR 0.1471156 for 27 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMERROR 0.1557694 for 49 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMERROR 0.1567308 for 19 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMERROR 0.1490384 for 25 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMERROR 0.1624998 for 18 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMERROR 0.1509616 for 39 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMERROR 0.1576924 for 31 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMERROR 0.15288459999999998 for 28 rounds\n",
      "Best params: 0.8, 1.0, MERROR: 0.1471156\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")  \n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=seed,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MERROR\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: 0.8, 1.0, MERROR: 0.1471156\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = .8\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter ETA\n",
    "The ETA parameter controls the learning rate. It corresponds to the shrinkage of the weights associated to features after each round, in other words it defines the amount of \"correction\" we make at each step.\n",
    "In practice, having a lower eta makes our model more robust to overfitting thus, usually, the lower the learning rate, the best. But with a lower eta, we need more boosting rounds, which takes more time to train, sometimes for only marginal improvements. Let's try a couple of values here, and time them with the notebook command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.5\n",
      "CPU times: user 1min 53s, sys: 156 ms, total: 1min 53s\n",
      "Wall time: 28.4 s\n",
      "\tMERROR 0.153846 for 22 rounds\n",
      "\n",
      "CV with eta=0.4\n",
      "CPU times: user 2min 40s, sys: 200 ms, total: 2min 40s\n",
      "Wall time: 40.3 s\n",
      "\tMERROR 0.15000000000000002 for 45 rounds\n",
      "\n",
      "CV with eta=0.3\n",
      "CPU times: user 2min 43s, sys: 224 ms, total: 2min 43s\n",
      "Wall time: 40.9 s\n",
      "\tMERROR 0.1471156 for 27 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "CPU times: user 4min 15s, sys: 224 ms, total: 4min 15s\n",
      "Wall time: 1min 4s\n",
      "\tMERROR 0.1509616 for 53 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: user 6min 34s, sys: 352 ms, total: 6min 34s\n",
      "Wall time: 1min 38s\n",
      "\tMERROR 0.1442308 for 60 rounds\n",
      "\n",
      "Best params: 0.1, MERROR: 0.1442308\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")  \n",
    "best_params = None\n",
    "\n",
    "for eta in [.5, .4 ,.3, .2, .1]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "\n",
    "    # Run and time CV\n",
    "    \n",
    "    %time cv_results = xgb.cv(params, dtrain, num_boost_round=num_boost_round, seed=seed, nfold=5, metrics=['merror'], early_stopping_rounds=10)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update best score\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\\n\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, MERROR: {}\".format(best_params, min_merror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the best eta of 0.1 takes 1 min 38 s for Merror of 0.144 where as with eta=0.3 we have 40.9s and merror of 0.147. SO we will choose eta=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"eta\"] = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final dictionary of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_child_weight': 5,\n",
       " 'eta': 0.3,\n",
       " 'subsample': 0.8,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'objective': 'multi:softmax',\n",
       " 'eval_metric': 'merror',\n",
       " 'num_class': 8,\n",
       " 'silent': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.3\n",
      "Will train until Test-merror hasn't improved in 10 rounds.\n",
      "[1]\tTest-merror:0.21875\n",
      "[2]\tTest-merror:0.21875\n",
      "[3]\tTest-merror:0.21875\n",
      "[4]\tTest-merror:0.21875\n",
      "[5]\tTest-merror:0.2125\n",
      "[6]\tTest-merror:0.2\n",
      "[7]\tTest-merror:0.18125\n",
      "[8]\tTest-merror:0.1875\n",
      "[9]\tTest-merror:0.18125\n",
      "[10]\tTest-merror:0.175\n",
      "[11]\tTest-merror:0.175\n",
      "[12]\tTest-merror:0.175\n",
      "[13]\tTest-merror:0.175\n",
      "[14]\tTest-merror:0.16875\n",
      "[15]\tTest-merror:0.1625\n",
      "[16]\tTest-merror:0.15\n",
      "[17]\tTest-merror:0.15625\n",
      "[18]\tTest-merror:0.15625\n",
      "[19]\tTest-merror:0.15625\n",
      "[20]\tTest-merror:0.1625\n",
      "[21]\tTest-merror:0.15625\n",
      "[22]\tTest-merror:0.15625\n",
      "[23]\tTest-merror:0.15625\n",
      "[24]\tTest-merror:0.15625\n",
      "[25]\tTest-merror:0.15625\n",
      "[26]\tTest-merror:0.15625\n",
      "Stopping. Best iteration:\n",
      "[16]\tTest-merror:0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MERROR: 0.15 in 17 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MERROR: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model:\n",
    "Although we found the best number of rounds, our model has been trained with more rounds than optimal, thus before using it for predictions, we should retrain it with the good number of rounds. Since we now the exact best num_boost_round, we don't need the early_stopping_round anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_child_weight': 5,\n",
       " 'eta': 0.3,\n",
       " 'subsample': 0.8,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'objective': 'multi:softmax',\n",
       " 'eval_metric': 'merror',\n",
       " 'num_class': 8,\n",
       " 'silent': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.3\n",
      "[1]\tTest-merror:0.21875\n",
      "[2]\tTest-merror:0.21875\n",
      "[3]\tTest-merror:0.21875\n",
      "[4]\tTest-merror:0.21875\n",
      "[5]\tTest-merror:0.2125\n",
      "[6]\tTest-merror:0.2\n",
      "[7]\tTest-merror:0.18125\n",
      "[8]\tTest-merror:0.1875\n",
      "[9]\tTest-merror:0.18125\n",
      "[10]\tTest-merror:0.175\n",
      "[11]\tTest-merror:0.175\n",
      "[12]\tTest-merror:0.175\n",
      "[13]\tTest-merror:0.175\n",
      "[14]\tTest-merror:0.16875\n",
      "[15]\tTest-merror:0.1625\n",
      "[16]\tTest-merror:0.15\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the test dataset and compute evaluation metrics with the scikit-learn function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_model.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.8 , 0.8 , 0.95, 0.95, 0.7 , 0.65, 1.  , 0.95]),\n",
       " array([0.88888889, 0.76190476, 0.95      , 0.73076923, 0.875     ,\n",
       "        0.72222222, 0.95238095, 0.95      ]),\n",
       " array([0.84210526, 0.7804878 , 0.95      , 0.82608696, 0.77777778,\n",
       "        0.68421053, 0.97560976, 0.95      ]),\n",
       " array([18, 21, 20, 26, 16, 18, 21, 20]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_pred, testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " conf_matrix = pd.crosstab(testlabels, y_pred, rownames=['True'], colnames= ['Predicted'], margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0\n",
       "True                                             \n",
       "0           16    2    0    0    1    1    0    0\n",
       "1            1   16    0    0    0    3    0    0\n",
       "2            0    0   19    1    0    0    0    0\n",
       "3            0    0    0   19    0    0    1    0\n",
       "4            1    0    0    3   14    1    0    1\n",
       "5            0    3    0    3    1   13    0    0\n",
       "6            0    0    0    0    0    0   20    0\n",
       "7            0    0    1    0    0    0    0   19"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Save Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = xgb.Booster()\n",
    "#loaded_model.load_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
