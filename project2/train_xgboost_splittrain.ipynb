{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize imports\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the user configs\n",
    "with open('room_recognition/conf/conf_xgboost.json') as f:    \n",
    "  config = json.load(f)\n",
    "\n",
    "# config variables\n",
    "\n",
    "seed      = config[\"seed\"]\n",
    "train_features_path   = config[\"train_features_path\"]\n",
    "train_labels_path   = config[\"train_labels_path\"]\n",
    "test_features_path   = config[\"test_features_path\"]\n",
    "test_labels_path   = config[\"test_labels_path\"]\n",
    "\n",
    "results     = config[\"results\"]\n",
    "classifier_path = config[\"classifier_path\"]\n",
    "\n",
    "num_classes   = config[\"num_classes\"]\n",
    "\n",
    "model_path=config[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train features and labels\n",
    "h5f_data_train  = h5py.File(train_features_path, 'r')\n",
    "h5f_label_train = h5py.File(train_labels_path, 'r')\n",
    "\n",
    "train_features_string = h5f_data_train['dataset_1']\n",
    "train_labels_string   = h5f_label_train['dataset_1']\n",
    "\n",
    "trainfeatures = np.array(train_features_string)\n",
    "trainlabels   = np.array(train_labels_string)\n",
    "\n",
    "h5f_data_train.close()\n",
    "h5f_label_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] features shape: (1040, 2048)\n",
      "[INFO] labels shape: (1040,)\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of features and labels\n",
    "print (\"[INFO] features shape: {}\".format(trainfeatures.shape))\n",
    "print (\"[INFO] labels shape: {}\".format(trainlabels.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainfeatures, trainlabels, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train) \n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective': 'multi:softmax'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters num_boost_round and early_stopping_rounds\n",
    "From https://cambridgespark.com/content/tutorials/hyperparameter-tuning-in-xgboost/index.html\n",
    "Since trees are built sequentially, instead of fixing the number of rounds at the beginning, we can test our model at each step and see if adding a new tree/round improves performance.\n",
    "\n",
    "To do so, we define a test dataset and a metric that is used to assess performance at each round. If performance haven't improved for N rounds (N is defined by the variable early_stopping_round), we stop the training and keep the best number of boosting rounds.\n",
    "\n",
    "\n",
    "Evaluation metrics for validation data is specified using 'eval_metric'\n",
    "merror: Multiclass classification error rate. It is calculated as #(wrong cases)/#(all cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = \"merror\"  #multiclass Classification error rate. (#wrong cases/ #all cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['num_class'] = 8\n",
    "params['silent'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.230769\n",
      "Will train until Test-merror hasn't improved in 10 rounds.\n",
      "[1]\tTest-merror:0.182692\n",
      "[2]\tTest-merror:0.192308\n",
      "[3]\tTest-merror:0.153846\n",
      "[4]\tTest-merror:0.134615\n",
      "[5]\tTest-merror:0.105769\n",
      "[6]\tTest-merror:0.115385\n",
      "[7]\tTest-merror:0.105769\n",
      "[8]\tTest-merror:0.105769\n",
      "[9]\tTest-merror:0.096154\n",
      "[10]\tTest-merror:0.086538\n",
      "[11]\tTest-merror:0.096154\n",
      "[12]\tTest-merror:0.096154\n",
      "[13]\tTest-merror:0.096154\n",
      "[14]\tTest-merror:0.096154\n",
      "[15]\tTest-merror:0.096154\n",
      "[16]\tTest-merror:0.105769\n",
      "[17]\tTest-merror:0.096154\n",
      "[18]\tTest-merror:0.096154\n",
      "[19]\tTest-merror:0.096154\n",
      "[20]\tTest-merror:0.096154\n",
      "Stopping. Best iteration:\n",
      "[10]\tTest-merror:0.086538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MERROR: 0.09 with 11 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MERROR: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the other hyperparameters, next we will use the cv function from XGBoost. It does cross-validation on the training dataset and returns a mean merror score.\n",
    "\n",
    " Here we will use a large number again fro num_boost_round and count on early_stopping_rounds to find the optimal number of rounds before reaching the maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.310906</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.026441</td>\n",
       "      <td>0.006280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.264939</td>\n",
       "      <td>0.042871</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.002591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241438</td>\n",
       "      <td>0.038071</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233957</td>\n",
       "      <td>0.042327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227552</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.212584</td>\n",
       "      <td>0.034398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.212595</td>\n",
       "      <td>0.036728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.202981</td>\n",
       "      <td>0.039528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.200842</td>\n",
       "      <td>0.039747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.206172</td>\n",
       "      <td>0.043787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.199750</td>\n",
       "      <td>0.043717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.200819</td>\n",
       "      <td>0.043723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.194408</td>\n",
       "      <td>0.037526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.193338</td>\n",
       "      <td>0.038244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.193327</td>\n",
       "      <td>0.037405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.193327</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.187985</td>\n",
       "      <td>0.038169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.186927</td>\n",
       "      <td>0.034566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.187996</td>\n",
       "      <td>0.035936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.182649</td>\n",
       "      <td>0.032559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.184788</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.182654</td>\n",
       "      <td>0.030238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.179446</td>\n",
       "      <td>0.032792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.179451</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.180515</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.178382</td>\n",
       "      <td>0.031585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.180521</td>\n",
       "      <td>0.030269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.179452</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.178388</td>\n",
       "      <td>0.028987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.177313</td>\n",
       "      <td>0.031722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.176243</td>\n",
       "      <td>0.030725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.175174</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.175174</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.173034</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.174104</td>\n",
       "      <td>0.032271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.173034</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.169832</td>\n",
       "      <td>0.031351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.171965</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.171965</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.173034</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.171971</td>\n",
       "      <td>0.029871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.171971</td>\n",
       "      <td>0.032087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.170901</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.171965</td>\n",
       "      <td>0.032043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.169832</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.167692</td>\n",
       "      <td>0.033997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0           0.310906         0.035761           0.026441          0.006280\n",
       "1           0.264939         0.042871           0.005075          0.002591\n",
       "2           0.241438         0.038071           0.000801          0.000654\n",
       "3           0.233957         0.042327           0.000000          0.000000\n",
       "4           0.227552         0.036747           0.000000          0.000000\n",
       "5           0.212584         0.034398           0.000000          0.000000\n",
       "6           0.212595         0.036728           0.000000          0.000000\n",
       "7           0.202981         0.039528           0.000000          0.000000\n",
       "8           0.200842         0.039747           0.000000          0.000000\n",
       "9           0.206172         0.043787           0.000000          0.000000\n",
       "10          0.199750         0.043717           0.000000          0.000000\n",
       "11          0.200819         0.043723           0.000000          0.000000\n",
       "12          0.194408         0.037526           0.000000          0.000000\n",
       "13          0.193338         0.038244           0.000000          0.000000\n",
       "14          0.193327         0.037405           0.000000          0.000000\n",
       "15          0.193327         0.039632           0.000000          0.000000\n",
       "16          0.187985         0.038169           0.000000          0.000000\n",
       "17          0.186927         0.034566           0.000000          0.000000\n",
       "18          0.187996         0.035936           0.000000          0.000000\n",
       "19          0.182649         0.032559           0.000000          0.000000\n",
       "20          0.184788         0.030620           0.000000          0.000000\n",
       "21          0.182654         0.030238           0.000000          0.000000\n",
       "22          0.179446         0.032792           0.000000          0.000000\n",
       "23          0.179451         0.030674           0.000000          0.000000\n",
       "24          0.180515         0.032413           0.000000          0.000000\n",
       "25          0.178382         0.031585           0.000000          0.000000\n",
       "26          0.180521         0.030269           0.000000          0.000000\n",
       "27          0.179452         0.030109           0.000000          0.000000\n",
       "28          0.178388         0.028987           0.000000          0.000000\n",
       "29          0.177313         0.031722           0.000000          0.000000\n",
       "30          0.176243         0.030725           0.000000          0.000000\n",
       "31          0.175174         0.031344           0.000000          0.000000\n",
       "32          0.175174         0.031344           0.000000          0.000000\n",
       "33          0.173034         0.030998           0.000000          0.000000\n",
       "34          0.174104         0.032271           0.000000          0.000000\n",
       "35          0.173034         0.030998           0.000000          0.000000\n",
       "36          0.169832         0.031351           0.000000          0.000000\n",
       "37          0.171965         0.032043           0.000000          0.000000\n",
       "38          0.171965         0.032043           0.000000          0.000000\n",
       "39          0.173034         0.031182           0.000000          0.000000\n",
       "40          0.171971         0.029871           0.000000          0.000000\n",
       "41          0.171971         0.032087           0.000000          0.000000\n",
       "42          0.170901         0.030732           0.000000          0.000000\n",
       "43          0.171965         0.032043           0.000000          0.000000\n",
       "44          0.169832         0.031893           0.000000          0.000000\n",
       "45          0.167692         0.033997           0.000000          0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=seed,\n",
    "    nfold=5,\n",
    "    metrics={'merror'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv returns a table where the rows correspond to the number of boosting trees used, Here we stopped after 45 trees.\n",
    "The 4 columns correspond to the mean and standard deviation of \"merror\" on the test dataset and on the train dataset. We will focus on improving the merror for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16769240000000002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-merror-mean'].min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters max_depth and min_child_weight:\n",
    "These parameters add constraints on the architecture of the trees.\n",
    "\n",
    "max_depth is the maximum number of nodes allowed from the root to the farthest leaf of a tree. Deeper trees can model more complex relationships by adding more nodes, but as we go deeper, splits become less relevant and are sometimes only due to noise, causing the model to overfit.\n",
    "min_child_weight is the minimum weight (or number of samples if all samples have a weight of 1) required in order to create a new node in the tree. A smaller min_child_weight allows the algorithm to create children that correspond to fewer samples, thus allowing for more complex trees, but again, more likely to overfit.\n",
    "Thus, those parameters can be used to control the complexity of the trees. It is important to tune them together in order to find a good trade-off between model bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(4,9)\n",
    "    for min_child_weight in range(1,4)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comment:\n",
    "\n",
    "float(\"Inf\") It acts as an unbounded upper value for comparison. This is useful for finding lowest values for something. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=4, min_child_weight=1\n",
      "\tMERROR 0.1634146 for 48 rounds\n",
      "CV with max_depth=4, min_child_weight=2\n",
      "\tMERROR 0.1570314 for 39 rounds\n",
      "CV with max_depth=4, min_child_weight=3\n",
      "\tMERROR 0.16450099999999998 for 50 rounds\n",
      "CV with max_depth=5, min_child_weight=1\n",
      "\tMERROR 0.1698204 for 25 rounds\n",
      "CV with max_depth=5, min_child_weight=2\n",
      "\tMERROR 0.163426 for 32 rounds\n",
      "CV with max_depth=5, min_child_weight=3\n",
      "\tMERROR 0.166629 for 35 rounds\n",
      "CV with max_depth=6, min_child_weight=1\n",
      "\tMERROR 0.16769240000000002 for 45 rounds\n",
      "CV with max_depth=6, min_child_weight=2\n",
      "\tMERROR 0.161281 for 38 rounds\n",
      "CV with max_depth=6, min_child_weight=3\n",
      "\tMERROR 0.1612982 for 32 rounds\n",
      "CV with max_depth=7, min_child_weight=1\n",
      "\tMERROR 0.15915339999999997 for 56 rounds\n",
      "CV with max_depth=7, min_child_weight=2\n",
      "\tMERROR 0.16128699999999999 for 26 rounds\n",
      "CV with max_depth=7, min_child_weight=3\n",
      "\tMERROR 0.1527476 for 45 rounds\n",
      "CV with max_depth=8, min_child_weight=1\n",
      "\tMERROR 0.1687622 for 47 rounds\n",
      "CV with max_depth=8, min_child_weight=2\n",
      "\tMERROR 0.16449519999999998 for 25 rounds\n",
      "CV with max_depth=8, min_child_weight=3\n",
      "\tMERROR 0.16343139999999998 for 57 rounds\n",
      "Best params: 7, 3, MERROR: 0.1527476\n"
     ]
    }
   ],
   "source": [
    "# Define initial best params and MAE\n",
    "min_merror = float(\"Inf\")  \n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=seed,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best score with a max_depth of 7 and min_child_weight of 3 ,  MERROR=0.152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 7\n",
    "params['min_child_weight'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters subsample and colsample_bytree\n",
    "Those parameters control the sampling of the dataset that is done at each boosting round.\n",
    "\n",
    "Instead of using the whole training set every time, we can build a tree on slightly different data at each step, which makes it less likely to overfit to a single sample or feature.\n",
    "\n",
    "subsample corresponds to the fraction of observations (the rows) to subsample at each step. By default it is set to 1 meaning that we use all rows.\n",
    "colsample_bytree corresponds to the fraction of features (the columns) to use. By default it is set to 1 meaning that we will use all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(1,10)]\n",
    "    for colsample in [i/10. for i in range(1,10)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMERROR 0.1644898 for 26 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMERROR 0.17088399999999998 for 32 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMERROR 0.16449560000000002 for 36 rounds\n",
      "CV with subsample=0.9, colsample=0.6\n",
      "\tMERROR 0.1623618 for 41 rounds\n",
      "CV with subsample=0.9, colsample=0.5\n",
      "\tMERROR 0.1794458 for 22 rounds\n",
      "CV with subsample=0.9, colsample=0.4\n",
      "\tMERROR 0.15807279999999996 for 71 rounds\n",
      "CV with subsample=0.9, colsample=0.3\n",
      "\tMERROR 0.1559448 for 35 rounds\n",
      "CV with subsample=0.9, colsample=0.2\n",
      "\tMERROR 0.1602228 for 25 rounds\n",
      "CV with subsample=0.9, colsample=0.1\n",
      "\tMERROR 0.16982599999999998 for 40 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMERROR 0.1516782 for 39 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMERROR 0.1580952 for 49 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMERROR 0.17838759999999998 for 21 rounds\n",
      "CV with subsample=0.8, colsample=0.6\n",
      "\tMERROR 0.17626579999999997 for 37 rounds\n",
      "CV with subsample=0.8, colsample=0.5\n",
      "\tMERROR 0.1762374 for 37 rounds\n",
      "CV with subsample=0.8, colsample=0.4\n",
      "\tMERROR 0.1772726 for 21 rounds\n",
      "CV with subsample=0.8, colsample=0.3\n",
      "\tMERROR 0.16448980000000002 for 35 rounds\n",
      "CV with subsample=0.8, colsample=0.2\n",
      "\tMERROR 0.16660579999999997 for 18 rounds\n",
      "CV with subsample=0.8, colsample=0.1\n",
      "\tMERROR 0.1719822 for 26 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMERROR 0.1623508 for 38 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMERROR 0.1591422 for 32 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMERROR 0.16341440000000002 for 37 rounds\n",
      "CV with subsample=0.7, colsample=0.6\n",
      "\tMERROR 0.1751904 for 28 rounds\n",
      "CV with subsample=0.7, colsample=0.5\n",
      "\tMERROR 0.171965 for 29 rounds\n",
      "CV with subsample=0.7, colsample=0.4\n",
      "\tMERROR 0.1666346 for 62 rounds\n",
      "CV with subsample=0.7, colsample=0.3\n",
      "\tMERROR 0.1612526 for 25 rounds\n",
      "CV with subsample=0.7, colsample=0.2\n",
      "\tMERROR 0.161287 for 31 rounds\n",
      "CV with subsample=0.7, colsample=0.1\n",
      "\tMERROR 0.17519040000000002 for 14 rounds\n",
      "CV with subsample=0.6, colsample=0.9\n",
      "\tMERROR 0.1709126 for 18 rounds\n",
      "CV with subsample=0.6, colsample=0.8\n",
      "\tMERROR 0.16554200000000002 for 48 rounds\n",
      "CV with subsample=0.6, colsample=0.7\n",
      "\tMERROR 0.16984320000000003 for 27 rounds\n",
      "CV with subsample=0.6, colsample=0.6\n",
      "\tMERROR 0.16557059999999998 for 24 rounds\n",
      "CV with subsample=0.6, colsample=0.5\n",
      "\tMERROR 0.17731239999999998 for 40 rounds\n",
      "CV with subsample=0.6, colsample=0.4\n",
      "\tMERROR 0.1719706 for 34 rounds\n",
      "CV with subsample=0.6, colsample=0.3\n",
      "\tMERROR 0.1751734 for 29 rounds\n",
      "CV with subsample=0.6, colsample=0.2\n",
      "\tMERROR 0.14952200000000002 for 36 rounds\n",
      "CV with subsample=0.6, colsample=0.1\n",
      "\tMERROR 0.1655592 for 55 rounds\n",
      "CV with subsample=0.5, colsample=0.9\n",
      "\tMERROR 0.167704 for 24 rounds\n",
      "CV with subsample=0.5, colsample=0.8\n",
      "\tMERROR 0.15808399999999997 for 50 rounds\n",
      "CV with subsample=0.5, colsample=0.7\n",
      "\tMERROR 0.1559278 for 41 rounds\n",
      "CV with subsample=0.5, colsample=0.6\n",
      "\tMERROR 0.15596200000000002 for 31 rounds\n",
      "CV with subsample=0.5, colsample=0.5\n",
      "\tMERROR 0.1666232 for 28 rounds\n",
      "CV with subsample=0.5, colsample=0.4\n",
      "\tMERROR 0.16661160000000003 for 43 rounds\n",
      "CV with subsample=0.5, colsample=0.3\n",
      "\tMERROR 0.16340880000000002 for 47 rounds\n",
      "CV with subsample=0.5, colsample=0.2\n",
      "\tMERROR 0.1548754 for 47 rounds\n",
      "CV with subsample=0.5, colsample=0.1\n",
      "\tMERROR 0.16877899999999998 for 31 rounds\n",
      "CV with subsample=0.4, colsample=0.9\n",
      "\tMERROR 0.1741324 for 21 rounds\n",
      "CV with subsample=0.4, colsample=0.8\n",
      "\tMERROR 0.16020020000000001 for 39 rounds\n",
      "CV with subsample=0.4, colsample=0.7\n",
      "\tMERROR 0.1612758 for 64 rounds\n",
      "CV with subsample=0.4, colsample=0.6\n",
      "\tMERROR 0.15811799999999998 for 37 rounds\n",
      "CV with subsample=0.4, colsample=0.5\n",
      "\tMERROR 0.17090680000000003 for 34 rounds\n",
      "CV with subsample=0.4, colsample=0.4\n",
      "\tMERROR 0.1847764 for 30 rounds\n",
      "CV with subsample=0.4, colsample=0.3\n",
      "\tMERROR 0.1730518 for 34 rounds\n",
      "CV with subsample=0.4, colsample=0.2\n",
      "\tMERROR 0.17625439999999998 for 23 rounds\n",
      "CV with subsample=0.4, colsample=0.1\n",
      "\tMERROR 0.17734119999999998 for 17 rounds\n",
      "CV with subsample=0.3, colsample=0.9\n",
      "\tMERROR 0.17948000000000003 for 22 rounds\n",
      "CV with subsample=0.3, colsample=0.8\n",
      "\tMERROR 0.1591478 for 41 rounds\n",
      "CV with subsample=0.3, colsample=0.7\n",
      "\tMERROR 0.17516759999999998 for 26 rounds\n",
      "CV with subsample=0.3, colsample=0.6\n",
      "\tMERROR 0.1645066 for 45 rounds\n",
      "CV with subsample=0.3, colsample=0.5\n",
      "\tMERROR 0.177301 for 60 rounds\n",
      "CV with subsample=0.3, colsample=0.4\n",
      "\tMERROR 0.1730686 for 44 rounds\n",
      "CV with subsample=0.3, colsample=0.3\n",
      "\tMERROR 0.16557059999999998 for 32 rounds\n",
      "CV with subsample=0.3, colsample=0.2\n",
      "\tMERROR 0.17732399999999998 for 21 rounds\n",
      "CV with subsample=0.3, colsample=0.1\n",
      "\tMERROR 0.18586299999999997 for 30 rounds\n",
      "CV with subsample=0.2, colsample=0.9\n",
      "\tMERROR 0.164501 for 31 rounds\n",
      "CV with subsample=0.2, colsample=0.8\n",
      "\tMERROR 0.16662879999999997 for 32 rounds\n",
      "CV with subsample=0.2, colsample=0.7\n",
      "\tMERROR 0.1655592 for 48 rounds\n",
      "CV with subsample=0.2, colsample=0.6\n",
      "\tMERROR 0.1644898 for 37 rounds\n",
      "CV with subsample=0.2, colsample=0.5\n",
      "\tMERROR 0.185846 for 31 rounds\n",
      "CV with subsample=0.2, colsample=0.4\n",
      "\tMERROR 0.18052120000000002 for 30 rounds\n",
      "CV with subsample=0.2, colsample=0.3\n",
      "\tMERROR 0.17837619999999998 for 23 rounds\n",
      "CV with subsample=0.2, colsample=0.2\n",
      "\tMERROR 0.17948 for 41 rounds\n",
      "CV with subsample=0.2, colsample=0.1\n",
      "\tMERROR 0.16237339999999997 for 49 rounds\n",
      "CV with subsample=0.1, colsample=0.9\n",
      "\tMERROR 0.22222080000000002 for 12 rounds\n",
      "CV with subsample=0.1, colsample=0.8\n",
      "\tMERROR 0.19976100000000002 for 29 rounds\n",
      "CV with subsample=0.1, colsample=0.7\n",
      "\tMERROR 0.1912278 for 35 rounds\n",
      "CV with subsample=0.1, colsample=0.6\n",
      "\tMERROR 0.1827114 for 46 rounds\n",
      "CV with subsample=0.1, colsample=0.5\n",
      "\tMERROR 0.19547180000000003 for 28 rounds\n",
      "CV with subsample=0.1, colsample=0.4\n",
      "\tMERROR 0.1954944 for 39 rounds\n",
      "CV with subsample=0.1, colsample=0.3\n",
      "\tMERROR 0.1890888 for 31 rounds\n",
      "CV with subsample=0.1, colsample=0.2\n",
      "\tMERROR 0.19866899999999998 for 46 rounds\n",
      "CV with subsample=0.1, colsample=0.1\n",
      "\tMERROR 0.18698960000000003 for 39 rounds\n",
      "Best params: 0.6, 0.2, MERROR: 0.14952200000000002\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")  \n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=seed,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MERROR\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: 0.6, 0.2, MERROR: 0.14952200000000002\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: {}, {}, MERROR: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = .6\n",
    "params['colsample_bytree'] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter ETA\n",
    "The ETA parameter controls the learning rate. It corresponds to the shrinkage of the weights associated to features after each round, in other words it defines the amount of \"correction\" we make at each step.\n",
    "In practice, having a lower eta makes our model more robust to overfitting thus, usually, the lower the learning rate, the best. But with a lower eta, we need more boosting rounds, which takes more time to train, sometimes for only marginal improvements. Let's try a couple of values here, and time them with the notebook command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.5\n",
      "CPU times: user 29.9 s, sys: 140 ms, total: 30.1 s\n",
      "Wall time: 7.6 s\n",
      "\tMERROR 0.17837660000000002 for 24 rounds\n",
      "\n",
      "CV with eta=0.4\n",
      "CPU times: user 49.6 s, sys: 212 ms, total: 49.9 s\n",
      "Wall time: 12.5 s\n",
      "\tMERROR 0.15702 for 62 rounds\n",
      "\n",
      "CV with eta=0.3\n",
      "CPU times: user 44.2 s, sys: 176 ms, total: 44.4 s\n",
      "Wall time: 11.1 s\n",
      "\tMERROR 0.14952200000000002 for 36 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "CPU times: user 43.4 s, sys: 176 ms, total: 43.6 s\n",
      "Wall time: 10.9 s\n",
      "\tMERROR 0.1634486 for 24 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: user 1min 4s, sys: 204 ms, total: 1min 4s\n",
      "Wall time: 16.1 s\n",
      "\tMERROR 0.15808379999999997 for 36 rounds\n",
      "\n",
      "Best params: 0.3, MERROR: 0.14952200000000002\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")  \n",
    "best_params = None\n",
    "\n",
    "for eta in [.5, .4 ,.3, .2, .1]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "\n",
    "    # Run and time CV\n",
    "    \n",
    "    %time cv_results = xgb.cv(params, dtrain, num_boost_round=num_boost_round, seed=seed, nfold=5, metrics=['merror'], early_stopping_rounds=10)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Update best score\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    print(\"\\tMERROR {} for {} rounds\\n\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, MERROR: {}\".format(best_params, min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"eta\"] = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final dictionary of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 3,\n",
       " 'eta': 0.3,\n",
       " 'subsample': 0.6,\n",
       " 'colsample_bytree': 0.2,\n",
       " 'objective': 'multi:softmax',\n",
       " 'eval_metric': 'merror',\n",
       " 'num_class': 8,\n",
       " 'silent': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use these parameters to train a model and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.317308\n",
      "Will train until Test-merror hasn't improved in 10 rounds.\n",
      "[1]\tTest-merror:0.25\n",
      "[2]\tTest-merror:0.182692\n",
      "[3]\tTest-merror:0.192308\n",
      "[4]\tTest-merror:0.153846\n",
      "[5]\tTest-merror:0.134615\n",
      "[6]\tTest-merror:0.125\n",
      "[7]\tTest-merror:0.125\n",
      "[8]\tTest-merror:0.125\n",
      "[9]\tTest-merror:0.115385\n",
      "[10]\tTest-merror:0.105769\n",
      "[11]\tTest-merror:0.115385\n",
      "[12]\tTest-merror:0.105769\n",
      "[13]\tTest-merror:0.105769\n",
      "[14]\tTest-merror:0.115385\n",
      "[15]\tTest-merror:0.125\n",
      "[16]\tTest-merror:0.105769\n",
      "[17]\tTest-merror:0.096154\n",
      "[18]\tTest-merror:0.115385\n",
      "[19]\tTest-merror:0.096154\n",
      "[20]\tTest-merror:0.096154\n",
      "[21]\tTest-merror:0.086538\n",
      "[22]\tTest-merror:0.086538\n",
      "[23]\tTest-merror:0.096154\n",
      "[24]\tTest-merror:0.105769\n",
      "[25]\tTest-merror:0.096154\n",
      "[26]\tTest-merror:0.096154\n",
      "[27]\tTest-merror:0.086538\n",
      "[28]\tTest-merror:0.086538\n",
      "[29]\tTest-merror:0.096154\n",
      "[30]\tTest-merror:0.086538\n",
      "[31]\tTest-merror:0.086538\n",
      "Stopping. Best iteration:\n",
      "[21]\tTest-merror:0.086538\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MERROR: 0.087 in 22 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best MERROR: {:.3f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out Merror has improved marginally from the original 0.09 on the validation set to 0.087b on the validation set after parameter\n",
    "tuning,\n",
    "Saving the model:\n",
    "Although we found the best number of rounds, our model has been trained with more rounds than optimal, thus before using it for predictions, we should retrain it with the good number of rounds. Since we now the exact best num_boost_round, we don't need the early_stopping_round anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 3,\n",
       " 'eta': 0.3,\n",
       " 'subsample': 0.6,\n",
       " 'colsample_bytree': 0.2,\n",
       " 'objective': 'multi:softmax',\n",
       " 'eval_metric': 'merror',\n",
       " 'num_class': 8,\n",
       " 'silent': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.317308\n",
      "[1]\tTest-merror:0.25\n",
      "[2]\tTest-merror:0.182692\n",
      "[3]\tTest-merror:0.192308\n",
      "[4]\tTest-merror:0.153846\n",
      "[5]\tTest-merror:0.134615\n",
      "[6]\tTest-merror:0.125\n",
      "[7]\tTest-merror:0.125\n",
      "[8]\tTest-merror:0.125\n",
      "[9]\tTest-merror:0.115385\n",
      "[10]\tTest-merror:0.105769\n",
      "[11]\tTest-merror:0.115385\n",
      "[12]\tTest-merror:0.105769\n",
      "[13]\tTest-merror:0.105769\n",
      "[14]\tTest-merror:0.115385\n",
      "[15]\tTest-merror:0.125\n",
      "[16]\tTest-merror:0.105769\n",
      "[17]\tTest-merror:0.096154\n",
      "[18]\tTest-merror:0.115385\n",
      "[19]\tTest-merror:0.096154\n",
      "[20]\tTest-merror:0.096154\n",
      "[21]\tTest-merror:0.086538\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at evaluation metrics with the scikit-learn function on the validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_model.predict(dtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.9       , 0.92307692, 1.        , 0.55555556, 0.91666667,\n",
       "        0.81818182, 1.        , 1.        ]),\n",
       " array([1.        , 0.85714286, 0.9375    , 1.        , 0.91666667,\n",
       "        0.64285714, 1.        , 1.        ]),\n",
       " array([0.94736842, 0.88888889, 0.96774194, 0.71428571, 0.91666667,\n",
       "        0.72      , 1.        , 1.        ]),\n",
       " array([ 9, 14, 16,  5, 12, 14, 15, 19]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    " conf_matrix = pd.crosstab(y_test, y_pred, rownames=['True'], colnames= ['Predicted'], margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0\n",
       "True                                             \n",
       "0            9    1    0    0    0    0    0    0\n",
       "1            0   12    0    0    0    1    0    0\n",
       "2            0    0   15    0    0    0    0    0\n",
       "3            0    0    0    5    1    3    0    0\n",
       "4            0    0    0    0   11    1    0    0\n",
       "5            0    1    1    0    0    9    0    0\n",
       "6            0    0    0    0    0    0   15    0\n",
       "7            0    0    0    0    0    0    0   19"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Save Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = xgb.Booster()\n",
    "#loaded_model.load_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
